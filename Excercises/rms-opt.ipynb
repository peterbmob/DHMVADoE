{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peterbmob/DHMVADoE/blob/main/Excercises/rms-opt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm4gfzWBkNbU"
      },
      "source": [
        "# RSM as sequential process for optimisation\n",
        "(adapted from https://online.stat.psu.edu/stat503/lesson/11)\n",
        "\n",
        "\n",
        "To find the maxima, we will use three different models\n",
        "\n",
        "- Screening response model\n",
        "- Steepest ascent model\n",
        "- Optimization model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnBUv_YpkNbV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-fO_hnNkNbW"
      },
      "source": [
        "## ## Screening Response Model\n",
        "In the first place, we do not know if there is a maxima so we start somewhere where we think the optimim exists. We start somewhere in terms where x1 = reaction time (30-40 seconds) and x2 = temperature (150-160 C), and we want to maximize the yeld of a process as function of these factors.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpoBtKnzkNbW"
      },
      "outputs": [],
      "source": [
        "inputs_labels = {'t' : 'Time',\n",
        "                 'T' : 'Temperature'}\n",
        "\n",
        "#create list of data for high and low.\n",
        "dat = [('t',30,35,40),\n",
        "        ('T',150,155,160)]\n",
        "\n",
        "# create pandas dataframe in a pandas dataframe\n",
        "inputs_df = pd.DataFrame(dat,columns=['index','low','center','high'])\n",
        "inputs_df = inputs_df.set_index(['index'])\n",
        "inputs_df['label'] = inputs_df.index.map( lambda z : inputs_labels[z] )\n",
        "\n",
        "#print dataframe\n",
        "inputs_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hF_foMnDkNbW"
      },
      "outputs": [],
      "source": [
        "# compute averages and span\n",
        "inputs_df['average'] = inputs_df.apply( lambda z : ( z['high'] + z['low'])/2 , axis=1)\n",
        "inputs_df['span'] = inputs_df.apply( lambda z : ( z['high'] - z['low'])/2 , axis=1)\n",
        "\n",
        "# encode the data\n",
        "inputs_df['encoded_low'] = inputs_df.apply( lambda z : ( z['low']  - z['average'] )/( z['span'] ), axis=1)\n",
        "inputs_df['encoded_center'] = inputs_df.apply( lambda z : ( z['center'] - z['average'] )/( z['span'] ), axis=1)\n",
        "inputs_df['encoded_high'] = inputs_df.apply( lambda z : ( z['high'] - z['average'] )/( z['span'] ), axis=1)\n",
        "\n",
        "inputs_df = inputs_df.drop(['average','span'],axis=1)\n",
        "\n",
        "inputs_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABOg91v_kNbX"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "encoded_inputs= list(itertools.product([-1,1],[-1,1]))\n",
        "encoded_inputs\n",
        "for i in range(0,5):\n",
        "    encoded_inputs.append((0,0))\n",
        "encoded_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxCge95wkNbX"
      },
      "outputs": [],
      "source": [
        "results=pd.DataFrame(encoded_inputs)\n",
        "results=results[results.columns[::-1]]\n",
        "results.columns=['t','T']\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWcrOLKGkNbX"
      },
      "outputs": [],
      "source": [
        "def parse_values(x):\n",
        "    if x < 2:\n",
        "       return x * 10\n",
        "    elif x < 4:\n",
        "       return x ** 2\n",
        "    else:\n",
        "       return x + 10\n",
        "\n",
        "real_experiment = results\n",
        "var_labels = []\n",
        "for var in ['t','T']:\n",
        "    var_label = inputs_df.loc[var]['label']\n",
        "    var_labels.append(var_label)\n",
        "    real_experiment[var_label] = results.apply(\n",
        "        lambda z : inputs_df.loc[var]['low'] if z[var]<0 else (inputs_df.loc[var]['high'] if z[var]>0 else inputs_df.loc[var]['center']),\n",
        "        axis=1)\n",
        "\n",
        "\n",
        "\n",
        "print(\"The values of each real variable in the experiment:\")\n",
        "real_experiment[var_labels]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i6Ey_l_kNbX"
      },
      "source": [
        "# add experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkosOqWykNbY"
      },
      "outputs": [],
      "source": [
        "y= [39.3, 40.9, 40.0, 41.5, 40.3, 40.5, 40.7, 40.2, 40.6]\n",
        "results['y']= y\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXwUHxvTkNbY"
      },
      "outputs": [],
      "source": [
        "# Data , 4 corners and 5 center points:\n",
        "\n",
        "df = pd.DataFrame(results,columns=['t','T','y'])\n",
        "#inputs_df = inputs_df.set_index(['index'])\n",
        "\n",
        "#print dataframe\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYUfoCxwkNbY"
      },
      "outputs": [],
      "source": [
        "# Compute the mean effect of the factor on the response,\n",
        "# conditioned on each variable\n",
        "labels = ['t','T']\n",
        "print('ybar is', results['y'].mean())\n",
        "main_effects = {}\n",
        "\n",
        "print('main effects')\n",
        "for key in labels:\n",
        "        average_effects = results.groupby(key)['y'].mean()\n",
        "        main_effects[key] = sum( [i*average_effects[i] for i in [-1,1]])\n",
        "print(main_effects)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmalwE3QkNbY"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "twoway_labels = list(itertools.combinations(labels, 2))\n",
        "\n",
        "\n",
        "twoway_effects = {}\n",
        "for key in twoway_labels:\n",
        "\n",
        "    effects = results.groupby([key[0],key[1]])['y'].mean()\n",
        "\n",
        "    twoway_effects[key] = sum([ i*j*effects[i][j]/2 for i in [-1,1] for j in [-1,1] ])\n",
        "twoway_effects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyVlLVAckNbY"
      },
      "source": [
        "Model is:\n",
        "\n",
        "ybar = 40.4444 + 1.55*t/2 + 0.65*T/2 -0.05*t*T/2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5ze09SZkNbZ"
      },
      "source": [
        "Alternative way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inaxYDRGkNbZ"
      },
      "outputs": [],
      "source": [
        "y1 = results['y']\n",
        "xlabs=['t','T']\n",
        "x = results[xlabs]\n",
        "x = sm.add_constant(x)\n",
        "\n",
        "res1 = smf.ols(formula='y ~ t + T + t:T', data=results).fit()\n",
        "\n",
        "res1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cN34OO-ikNbZ"
      },
      "source": [
        "So, we have now fitted the surface, either using our standard approach or using OLS. The model has two main effects, one cross product term and one additional parameter as the mean for the center point. The residulas in this case have 5 degrees of freedom which come from the replicaiton of the center points. This is a measure of the pure error.\n",
        "\n",
        "Next we check for significant effects... we see that the effect of the cross-product that there is no interaction. This mean that we can refit the model without the interaction term, leaving us with only t and T."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgK6RdvtkNbZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "est1 = sm.OLS(y1,x).fit()\n",
        "print(est1.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEZIo2czkNbZ"
      },
      "source": [
        "This leaves with the first order model:\n",
        "ybar = 40.444 + 0.775t + 0.325T\n",
        "\n",
        "So, now, for any t and T, we can predict y. This fits a flat surface and it tells us that the predicted y is a function of x1 and x2 and the coefficients are the gradient of this function. We are working in coded variables, which means that the coefficients are unitless.\n",
        "\n",
        "If we move 0.775 in the direction of t and then 0.325 in the direction of T, this will be the direction of steepest ascent. All we know is that this flat surface is one side of the \"hill\" forming our maxima.\n",
        "\n",
        "\n",
        "With the method of steepest descent, we can now start marching up the hill taking additional measurements at each (t,T) until the response starts to decrease. If we start at 0 (in coded units), then we can do series of single experiments on this path up the hill of the steepest ascent. If swe do this at a step size of t=1, then:\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{1}{0.775}=\\frac{T}{0.325} \\rightarrow T = \\frac{0.325}{0.775} = 0.42\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzkAzQD8kNbZ"
      },
      "outputs": [],
      "source": [
        "Origin = [0,0]\n",
        "delta= [1.0,0.42]\n",
        "y=[41.0,42.9,47.1,49.7,53.8,59.9,65.0,70.4,77.6,80.3,76.2,75.1]\n",
        "\n",
        "march=[]\n",
        "for i in range(0,len(y)):\n",
        "    march.append((Origin[0]+(i+1)*delta[0],Origin[1]+(i+1)*delta[1],y[i]))\n",
        "\n",
        "March=pd.DataFrame(march,columns=['t', 'T', 'y'])\n",
        "March"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39vFr2CzkNbZ"
      },
      "outputs": [],
      "source": [
        "ax=March['y'].plot()\n",
        "ax.set_xlabel(\"step\")\n",
        "ax.set_ylabel(\"Yield\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7d-QOfrkNbZ"
      },
      "source": [
        "This is a pretty smooth curve and in reality, you probably should go a little bit more beyond the peak to make sure you are at the peak. But all you are trying to do is to find out approximately where the top of the 'hill' is. If your first experiment is not exactly right you might have gone off in the wrong direction!\n",
        "\n",
        "You might want to do another first-order experiment just to be sure. Or, you might wish to do a second order experiment, assuming you are near the top. The second order experiment will help find a more exact location of the peak.\n",
        "\n",
        "The point is, this is a fairly cheap way to 'scout around the mountain' to try to find where the optimum conditions are. Remember, this example is being shown in two dimensions but you may be working in three or four-dimensional space! You can use the same method, fitting a first-order model and then moving up the response surface in k dimensional space until you think you are close to where the optimal conditions are.\n",
        "\n",
        "If you are in more than 2 dimensions, you will not be able to get a nice plot. But that is OK. The method of steepest ascent tells you where to take new measurements, and you will know the response at those points. You might move a few steps and you may see that the response continued to move up or perhaps not - then you might do another first order experiment and redirect your efforts. The point is, when we do the experiment for the second order model, we hope that the optimum will be in the range of the experiment - if it is not, we are extrapolating to find the optimum. In this case, the safest thing to do is to do another experiment around this estimated optimum. Since the experiment for the second order model requires more runs than experiments for the first order model, we want to move into the right region before we start fitting second-order models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07STKnG2kNbZ"
      },
      "source": [
        "## Steepest Ascent - The Second Order Model\n",
        "\n",
        "\\begin{equation}\n",
        "y=\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_{12} x_1 x_2 + \\beta_{11} x_1^2 + \\beta_{22} x_2^2 + \\epsilon\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "This second order model includes linear terms, cross product terms and a second order term for each of the x's.  If we generalize this to x's, we have first order terms, second order terms and then we have all possible pairwise first-order interactions. The linear terms just have one subscript. The quadratic terms have two subscripts. There are $\\frac{k*(k-1)}{2} interaction terms. To fit this model, we are going to need a response surface design that has more runs than the first order designs used to move close to the optimum.\n",
        "\n",
        "This second order model is the basis for response surface designs under the assumption that although the hill is not a perfect quadratic polynomial in k dimensions, it provides a good approximation to the surface near the maximum or a minimum.\n",
        "\n",
        "Assuming that we have 'marched up this hill' and if we re-specified the region of interest in our example, we are now between 80 - 90 in terms of time and 170 - 180 in terms of temperature. We would now translate these natural units into our coded units and if we fit the first order model again, hopefully we can detect that the middle is higher than the corner points so we would have curvature in our model, and could now fit a quadratic polynomial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku_xNmD1kNbZ"
      },
      "source": [
        "## Polynomial regression\n",
        "Despite its name, linear regression can be used to fit non-linear functions. A linear regression model is linear in the model parameters, not necessarily in the predictors. If you add non-linear transformations of your predictors to the linear regression model, the model will be non-linear in the predictors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sX58nO_xkNba"
      },
      "outputs": [],
      "source": [
        "res2 = smf.ols(formula='y ~ t + T + t:T + I(t**2) + I(T**2)', data=March).fit()\n",
        "print(res2.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How do we find the maximum?"
      ],
      "metadata": {
        "id": "9RQ7LpHbICWH"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "course_book_II",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}