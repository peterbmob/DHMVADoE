{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJy6JuoNo1rfYnV9QElE8q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peterbmob/DHMVADoE/blob/main/Excercises/PCA_ex_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Principal Component Analysis\n",
        "\n",
        "Adapted from The E-Learning project SOGA-Py was developed at the Department of Earth Sciences by Annette Rudolph, Joachim Krois and Kai Hartmann. You can reach us via mail by soga[at]zedat.fu-berlin.de."
      ],
      "metadata": {
        "id": "ngLZGv2HAI5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us consider a problem with m observations/measurements on a set of n variables,\n",
        "$$x_1, x_2,...,x_n$$\n",
        "\n",
        "If n is a high number, exploratory data analysis becomes challenging, as for example our ability to visualize data is limited to 2 or 3 dimensions. We may explore the data set by examining two-dimensional scatter plots, each of which contains m observations and two of the n variables. However, there are\n",
        "$$\\binom{n}{2}= n(n-1)/2 $$ such scatter plots. If a data set has\n",
        "$$n= 15$$\n",
        "variables there are 105 plots to draw! Moreover, it is very likely that none of them will be informative since they each contain just a small fraction of the total information present in the data set. Hence, we are looking for a low-dimensional (d≪n) representation of the data that captures as much of the information as possible.\n",
        "\n",
        "Besides exploratory data analysis dimensionality reduction becomes important, if the features of a given data set are redundant. or, in other words, if they are highly correlated ([multicollinearity](https://en.wikipedia.org/wiki/Multicollinearity)). Multicollinearity is a problem because it causes instability in regression models. The redundant information inflates the variance of the parameter estimates which can cause them to be statistically insignificant when they would have been significant otherwise. Hence, we are looking for a low-dimensional representation of the data, where the features are uncorrelated with one another.\n",
        "\n",
        "One technique that provides such a dimensionality reduction is [Principal Component Analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis), which projects a high-dimensional variable space onto a new feature space. The original explanatory variables are replaced with new variables (features), derived from the original ones, that are by design uncorrelated with one another, thus eliminating the redundancy.\n",
        "\n",
        "The main idea behind PCA is that not all of the n dimensions of the original data set are equally informative, where the concept of being informative is measured by the variability along each particular variable space dimension, also denoted as variance. More precisely, PCA finds the directions of maximum variance in high-dimensional data and projects it onto a smaller dimensional subspace while retaining the main information. Each of the dimensions found by PCA is effectively a linear combination of the n variables."
      ],
      "metadata": {
        "id": "nM0GOrQARI-M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Principal Component Analysis - the basics\n",
        "Principal component analysis (PCA) allows us to summarize a set of variables with a smaller number of representative features that collectively explain most of the variability in the original data set. PCA projects the observations described by n variables into **orthogonal**, and thus by definition **uncorrelated**, features/variables. The new set of synthetic variables is equal in number to the original set. However, the first synthetic variable represents as much of the common variation of the original variables as possible, the second variable represents as much of the residual variation as possible, and so forth.\n",
        "\n",
        "PCA is particularly powerful in dealing with multicollinearity and observations that outnumber the variables (m>n), and it is widely used for explanatory data analysis, outlier detection and as a data pre-processing technique for predictive modelling. The figure below outlines the analysis workflow."
      ],
      "metadata": {
        "id": "lCd4itXhSphy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In predictive modelling PCA is particular useful as a data pre-processing technique. PCA serves as a tool for exploratory data analysis and outlier detection, but as well for dimensionality reduction when the number of variables outnumbers the sample size (d>n). Beyond that PCA is often applied on data sets with highly redundant variables, or in other words of highly correlated variables (problem of multicollinearity). Multicollinearity is a problem because it causes instability in regression models. The redundant information inflates the variance of the parameter estimates which can cause them to be statistically insignificant when they would have been significant otherwise.\n",
        "\n"
      ],
      "metadata": {
        "id": "UhCKSWCHP9FM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's  look more into detail using an example. First, we load the libraries we need for further analysis"
      ],
      "metadata": {
        "id": "8ADGNeScMBz0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15qzLfje_uol"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data and Data preparation\n",
        "\n",
        "To procceed a PCA on a given data set, we will first take a look at the data set. In this section we analyse the food texture data set. This open source data set is available here and describes texture measurements of a pastry-type food."
      ],
      "metadata": {
        "id": "qhRkbMg2G4d5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "food = pd.read_csv(\"https://userpage.fu-berlin.de/soga/data/raw-data/food-texture.csv\")\n",
        "# exclude first column\n",
        "food = food.iloc[:, 1:]\n",
        "food.head()"
      ],
      "metadata": {
        "id": "3SLeAbwhAS70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data set consists of 50 rows (observations) and 6 columns (features/variables). The features are:\n",
        "\n",
        "- Oil: percentage oil in the pastry\n",
        "- Density: the product’s density (the higher the number, the more dense the product)\n",
        "- Crispy: a crispiness measurement, on a scale from 7 to 15, with 15 being more crispy.\n",
        "- Fracture: the angle, in degrees, through which the pasty can be slowly bent before it fractures.\n",
        "- Hardness: a sharp point is used to measure the amount of force required before breakage occurs.\n",
        "\n",
        "For the sake of comprehensibility we start working with a reduced, two-dimensional toy data set, by extracting the columns Oil and Density. Later we return to the full data set for our analyses."
      ],
      "metadata": {
        "id": "KWBV_qG1HSOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_toy = food[[\"Oil\", \"Density\"]]\n",
        "pca_toy.head()"
      ],
      "metadata": {
        "id": "Aaexlls1GmG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start with an exploratory data analysis and examine a scatter plot.\n"
      ],
      "metadata": {
        "id": "xschJLitHz69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_toy.plot.scatter(x='Oil',y='Density')"
      ],
      "metadata": {
        "id": "Fp_Pu5EHH0uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler().fit(pca_toy)\n",
        "pca_toy_standard = pca_toy.copy()\n",
        "pca_toy_standard[[\"Oil\", \"Density\"]] = scaler.transform(pca_toy)\n",
        "pca_toy_standard.head()"
      ],
      "metadata": {
        "id": "xd4Hv7rIUIPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Scale the data\n",
        "The scatter plot above indicates a relationship between the feature Oil and the feature Density. Note that the variables are not on the same scale. In general, the results of PCA depend on the scale of the variables. Therefore, each variable is typically centered and scaled to have a mean of zero and standard deviation of one. In certain settings, however, the variables are measured in the same units, and one may skip the standardization.\n",
        "\n",
        "For the sake of comprehensibility we use the `StandardScaler` of scikit-learn and visualize the effects of each pre-processing step. The goal is to center each column to zero mean and then scale it to have unit variance.\n",
        "\n"
      ],
      "metadata": {
        "id": "ok2XqR7tTu23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set figure properties\n",
        "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
        "fig.subplots_adjust(hspace=0.5, wspace=0.3)\n",
        "axs = axs.ravel()\n",
        "\n",
        "# Scatterplot 1\n",
        "axs[0].scatter(pca_toy[[\"Oil\"]], pca_toy[[\"Density\"]])\n",
        "axs[0].set_title(\"Raw data\")\n",
        "data_mean = np.mean(pca_toy, axis=0)\n",
        "axs[0].scatter(data_mean[0], data_mean[1], color=\"red\", marker=\"o\")  # mark mean\n",
        "# Boxplot 1\n",
        "axs[1].boxplot(pca_toy)\n",
        "axs[1].set_title(\"Raw data\")\n",
        "\n",
        "# Scatterplot 2\n",
        "axs[2].scatter(pca_toy_standard[[\"Oil\"]], pca_toy_standard[[\"Density\"]])\n",
        "axs[2].set_title(\"Scaled and centered data\")\n",
        "data_mean = np.mean(pca_toy_standard, axis=0)\n",
        "axs[2].scatter(data_mean[0], data_mean[1], color=\"red\", marker=\"o\")  # mark mean\n",
        "# Boxplot 3\n",
        "axs[3].boxplot(pca_toy_standard)\n",
        "axs[3].set_title(\"Scaled and centered data\")\n",
        "\n",
        "# Assign pre-processed dataset to a new variable\n",
        "pca_toy_data = pca_toy_standard.reset_index()\n",
        "\n",
        "# save for later usage\n",
        "pca_toy_data.to_feather(\"pca_food_toy_30300.feather\")"
      ],
      "metadata": {
        "id": "2Hy1bFcyTy-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's go back to the full matrix"
      ],
      "metadata": {
        "id": "K2Lp9wuEoa49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performing a PCA\n"
      ],
      "metadata": {
        "id": "YuOr5ceYKxLf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we use StandardScaler instead to center and scale the data."
      ],
      "metadata": {
        "id": "eGvObW9RMa-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler().fit(food)\n",
        "food_scaled = scaler.transform(food)\n",
        "food_scaled=pd.DataFrame(food_scaled,columns=food.columns)\n",
        "food_scaled.head()"
      ],
      "metadata": {
        "id": "glimRUs2NYCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the data. A simple way to this is to use seaborn and the pairplot function."
      ],
      "metadata": {
        "id": "nkwFk4Yhohm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.pairplot(food_scaled, corner=True)"
      ],
      "metadata": {
        "id": "32BXS-i7o9oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lets do the PCA..."
      ],
      "metadata": {
        "id": "rWMQv8cZ1kEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "food_pca = PCA().fit(food_scaled)\n"
      ],
      "metadata": {
        "id": "A8QYd-cXObrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpretation and visualization of the PCA"
      ],
      "metadata": {
        "id": "0RhGNOByMoz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start by collecting the data\n",
        "\n"
      ],
      "metadata": {
        "id": "8bk2KxaZ16L7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "food_pca_eigen = pd.DataFrame(\n",
        "    food_pca.components_.T,\n",
        "    columns=[\"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\"],\n",
        "    index=food_scaled.columns,\n",
        ")\n",
        "\n",
        "# Compute the loadings\n",
        "food_pca_data=pd.DataFrame()\n",
        "food_pca_data[\"PC\"]=food_pca_eigen.columns\n",
        "food_pca_data[\"Explained Variance\"] = food_pca.explained_variance_\n",
        "food_pca_data[\"Explained Variance Ratio\"] = food_pca.explained_variance_ratio_\n",
        "food_pca_data.set_index('PC')\n",
        "\n",
        "# Compute the scores\n",
        "food_pca_scores = pd.DataFrame(\n",
        "    food_pca.transform(food_scaled),\n",
        "    columns=[\"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\"],\n",
        "    index=food_scaled.index,\n",
        ")"
      ],
      "metadata": {
        "id": "iB0ZGb0w15Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's inspect the data...\n",
        "\n",
        "We start with the Explained Variance and the Explained Variance Ratio.\n",
        "\n"
      ],
      "metadata": {
        "id": "XggZFBxT3-kZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
        "fig.subplots_adjust(hspace=0.5, wspace=0.3)\n",
        "axs = axs.ravel()\n",
        "\n",
        "food_pca_data.plot(x='PC',y='Explained Variance Ratio', ax=axs[0])\n",
        "food_pca_data.plot(x='PC',y='Explained Variance', ax=axs[1])\n"
      ],
      "metadata": {
        "id": "blrNPj1o9lYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We note that PC1 and PC2 explaines together a sigificant portion of the variance. Using he criterion, we can remove PC3-PC5. Let us look in more detail on PC1 and PC2."
      ],
      "metadata": {
        "id": "pCRC-DlY_WAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "food_pca_eigen"
      ],
      "metadata": {
        "id": "fuXp2BY0_VVh",
        "outputId": "7363fa57-27f1-4112-9c13-2bae627e3adc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               PC1       PC2       PC3       PC4       PC5\n",
              "Oil      -0.457533  0.370439 -0.659030 -0.467945 -0.012041\n",
              "Density   0.478745 -0.356750 -0.016240 -0.718463 -0.356482\n",
              "Crispy   -0.532388 -0.197661  0.178884  0.132527 -0.792421\n",
              "Fracture  0.504477  0.221240 -0.542279  0.456932 -0.440116\n",
              "Hardness -0.153403 -0.804666 -0.489233  0.196184  0.226148"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b19723e-4c22-4773-97b7-04f1f51f58c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PC1</th>\n",
              "      <th>PC2</th>\n",
              "      <th>PC3</th>\n",
              "      <th>PC4</th>\n",
              "      <th>PC5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Oil</th>\n",
              "      <td>-0.457533</td>\n",
              "      <td>0.370439</td>\n",
              "      <td>-0.659030</td>\n",
              "      <td>-0.467945</td>\n",
              "      <td>-0.012041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Density</th>\n",
              "      <td>0.478745</td>\n",
              "      <td>-0.356750</td>\n",
              "      <td>-0.016240</td>\n",
              "      <td>-0.718463</td>\n",
              "      <td>-0.356482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Crispy</th>\n",
              "      <td>-0.532388</td>\n",
              "      <td>-0.197661</td>\n",
              "      <td>0.178884</td>\n",
              "      <td>0.132527</td>\n",
              "      <td>-0.792421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fracture</th>\n",
              "      <td>0.504477</td>\n",
              "      <td>0.221240</td>\n",
              "      <td>-0.542279</td>\n",
              "      <td>0.456932</td>\n",
              "      <td>-0.440116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hardness</th>\n",
              "      <td>-0.153403</td>\n",
              "      <td>-0.804666</td>\n",
              "      <td>-0.489233</td>\n",
              "      <td>0.196184</td>\n",
              "      <td>0.226148</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b19723e-4c22-4773-97b7-04f1f51f58c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5b19723e-4c22-4773-97b7-04f1f51f58c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5b19723e-4c22-4773-97b7-04f1f51f58c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0a4dda26-18c5-437d-8ca9-313f89eaaeda\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a4dda26-18c5-437d-8ca9-313f89eaaeda')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0a4dda26-18c5-437d-8ca9-313f89eaaeda button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can look at the data for each PC in a bar plot"
      ],
      "metadata": {
        "id": "YWHGvt1i61a7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
        "fig.subplots_adjust(hspace=0.5, wspace=0.3)\n",
        "axs = axs.ravel()\n",
        "food_pca_eigen['PC1'].plot.bar(ax=axs[0])\n",
        "food_pca_scores['PC1'].plot(ax=axs[1], marker='s', linestyle='None')\n",
        "\n",
        "food_pca_eigen['PC2'].plot.bar(ax=axs[2])\n",
        "food_pca_scores['PC2'].plot(ax=axs[3], marker='s', linestyle='None')"
      ],
      "metadata": {
        "id": "pKAdEPqy2Vqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actually we can look at all at the same time:\n"
      ],
      "metadata": {
        "id": "7Gh8tkWo4EG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "food_pca_eigen.plot.bar()\n"
      ],
      "metadata": {
        "id": "p3NQBy_y3Mxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also look at the score plot plotted in the PC1-PC2 space"
      ],
      "metadata": {
        "id": "FXmlEr1B8Aoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the scores\n",
        "sns.scatterplot(data=food_pca_scores, x=\"PC1\", y=\"PC2\")\n",
        "plt.axhline(0, color=\"blue\")\n",
        "plt.axvline(0, color=\"green\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aY4tgX78MutJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Points close the average appear at the origin of the score plot. An observation that is at the mean value for all **k**-variables will have a score vector $$z_i = [0,0,...,0].$$\n",
        "- Scores further out are either outliers or naturally extreme observations.\n",
        "- Original observations in **X** that are similar to each other will be similar in the score plot, while observations much further apart are dissimilar. It is much easier to detect this similarity in an **k**-dimensional space than the original **d**-dimensional space, when **d**≫**k**."
      ],
      "metadata": {
        "id": "vOHMF_EKPVgi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loadings plot is a plot of the direction vectors that define the model. They show how the original variables contribute to creating the principal component.\n",
        "\n"
      ],
      "metadata": {
        "id": "EO9rrGCdP5Hs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loadings\n",
        "sns.scatterplot(data=food_pca_eigen, x=\"PC1\", y=\"PC2\")\n",
        "plt.axhline(0, color=\"blue\")\n",
        "plt.axvline(0, color=\"green\")\n",
        "plt.xlim(-1, 1)\n",
        "plt.ylim(-1, 1)\n",
        "\n",
        "# Plot annotations\n",
        "for i in range(food_pca_eigen.shape[0]):\n",
        "    plt.text(\n",
        "        food_pca_eigen[\"PC1\"][i],\n",
        "        food_pca_eigen[\"PC2\"][i],\n",
        "        food_pca_eigen.index[i],\n",
        "        color=\"red\",\n",
        "    )\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zUhDeVTeP_RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Variables which have little contribution to a direction have almost zero weight in that loading.\n",
        "- Variables which have roughly equal influence on defining a direction are correlated with each other and will have roughly equal numeric weights.\n",
        "- Strongly correlated variables, will have approximately the same weight value when they are positively correlated. In a loadings plot of e.g. p$_1$ vs p$_2$ they will appear near each other, while negatively correlated variables will appear diagonally opposite each other.\n",
        "-Signs of the loading variables are useful to compare within a direction vector; but these vectors can be rotated by 180° and still have the same interpretation."
      ],
      "metadata": {
        "id": "a4QlYLZQQLbz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The biplot is a very popular way for visualization of results from PCA, as it combines both the principal component scores and the loading vectors in a single biplot display."
      ],
      "metadata": {
        "id": "ORCCgchBQZ_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Biplot\n",
        "sns.scatterplot(\n",
        "    data=food_pca_scores,\n",
        "    x=\"PC1\",\n",
        "    y=\"PC2\",\n",
        "    hue=food_pca_scores.index,\n",
        "    legend=False,\n",
        ")\n",
        "plt.axhline(0, color=\"blue\")\n",
        "plt.axvline(0, color=\"green\")\n",
        "\n",
        "# plot the variables as vectors\n",
        "plt.quiver(\n",
        "    np.zeros(food_pca_eigen.shape[0]),\n",
        "    np.zeros(food_pca_eigen.shape[0]),\n",
        "    food_pca_eigen[\"PC1\"],\n",
        "    food_pca_eigen[\"PC2\"],\n",
        "    food_pca_eigen[\"eigenvalue\"],\n",
        "    angles=\"xy\",\n",
        "    scale_units=\"xy\",\n",
        "    scale=1,\n",
        ")\n",
        "\n",
        "# Plot annotations\n",
        "for i in range(food_pca_eigen.shape[0]):\n",
        "    plt.text(\n",
        "        food_pca_eigen[\"PC1\"][i],\n",
        "        food_pca_eigen[\"PC2\"][i],\n",
        "        food_pca_eigen.index[i],\n",
        "        color=\"red\",\n",
        "    )"
      ],
      "metadata": {
        "id": "OnJV4tU_Qhal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot shows the observations as points in the plane formed by two principal components (synthetic variables). Like for any scatterplot we may look for patterns, clusters, and outliers.\n",
        "\n",
        "In addition to the observations the plot shows the original variables as vectors (arrows). They begin at the origin [0,0] and extend to coordinates given by the loading vector (see loading plot above). These vectors can be interpreted in three ways:\n",
        "\n",
        "- The orientation (direction) of the vector, with respect to the principal component space, in particular, its angle with the principal component axes: the more parallel to a principal component axis is a vector, the more it contributes only to that PC.\n",
        "- The length in the space; the longer the vector, the more variability of this variable is represented by the two displayed principal components; short vectors are thus better represented in other dimension.\n",
        "- The angles between vectors of different variables show their correlation in this space: small angles represent high positive correlation, right angles represent lack of correlation, opposite angles represent high negative correlation."
      ],
      "metadata": {
        "id": "F8UlFJ_DQoCo"
      }
    }
  ]
}